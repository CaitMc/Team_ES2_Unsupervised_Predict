{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Overview: Movie Recommendation** \n",
    "\n",
    "![](https://about.netflix.com/images/meta/netflix-symbol-black.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.…ever wondered how Netflix, Amazon Prime, Showmax, Disney and the likes somehow know what to recommend to you?\n",
    "\n",
    "#### …it's not just a guess drawn out of the hat. There is an algorithm behind it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With this context, EDSA is challenging you to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "#### What value is achieved through building a functional recommender system?Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.\n",
    "\n",
    "\n",
    "#### This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems, and now you get to as well!\n",
    "\n",
    "#### For this Predict, we'll be using a special version of the MovieLens dataset which has enriched with additional data, and resampled for fair evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "# **Table of Contents**\n",
    "\n",
    "<details>\n",
    "<summary><a href=#one>1. Importing Packages</a></summary>\n",
    "<br>\n",
    "<a href=#one.one>1.1 Importing python packages that will be used in the notebook </a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#two>2. Loading Data</a></summary>\n",
    "<br>\n",
    "<a href=#two.one>2.1 Loading the Train and Test datasets</a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#three>3. Exploratory Data Analysis (EDA)</a></summary>\n",
    "<br>\n",
    "<a href=#three.one>3.1 Why is EDA important?</a>\n",
    "<br>\n",
    "<a href=#three.two>3.2 Pandas profiling model</a>\n",
    "<br>\n",
    "<a href=#three.three>3.3 Generating a word cloud</a>\n",
    "<br>\n",
    "<a href=#three.four>3.4 Looking at the data types of the Train and Test datasets</a>\n",
    "<br>\n",
    "<a href=#three.five>3.5 Looking for null values in the Train and Test datasets</a>\n",
    "<br>\n",
    "<a href=#three.six>3.6 Investigating the distribution of categorical values</a>\n",
    "<br>\n",
    "<a href=#three.seven> 3.7  Hashtags for each sentiment</a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#four>4. Data Engineering</a></summary>\n",
    "<br>\n",
    "<a href=#four.one>4.1 A copy of each dataset </a>\n",
    "<br>\n",
    "<a href=#four.two>4.2 Function to make all text lowercase </a>\n",
    "<br>\n",
    "<a href=#four.three>4.3 Function to remove URLs </a>\n",
    "<br>\n",
    "<a href=#four.four>4.4 Removing special characters </a>\n",
    "<br>\n",
    "<a href=#four.five>4.5 Removing punctuation </a>\n",
    "<br>\n",
    "<a href=#four.six>4.6 Removing digits</a>\n",
    "<br>\n",
    "<a href=#four.seven>4.7 Removing stopwords </a>\n",
    "<br>\n",
    "<a href=#four.eight>4.8 Tokenization </a>\n",
    "<br>\n",
    "<a href=#four.nine>4.9 Lemmatization </a>\n",
    "<br>\n",
    "<a href=#four.ten>4.10 Datasets after cleaning </a>\n",
    "<br>\n",
    "<a href=#four.eleven>4.11 Analysis of data after cleaning </a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#four>5. Modeling</a></summary>\n",
    "<br>\n",
    "<a href=#five.one>5.1 Splitting the x variable from the tartget variable </a>\n",
    "<br>\n",
    "<a href=#five.two>5.2 Turning text into something the model can read </a>\n",
    "<br>\n",
    "<a href=#five.three>5.3 Splitting the data into Train and validation set </a>\n",
    "<br>\n",
    "<a href=#four.four>4.4 Training the model and evaluating the model with the validation set </a>\n",
    "<br>\n",
    "<a href=#five.five>5.5 Logistic Regression model </a>\n",
    "<br>\n",
    "<a href=#five.six>5.6 Random Forest model </a>\n",
    "<br>\n",
    "<a href=#five.seven>5.7 Naive model</a>\n",
    "<br>\n",
    "<a href=#five.eight>5.8 SVC model </a>\n",
    "<br>\n",
    "<a href=#five.nine>5.9 KNN model </a>\n",
    "<br>\n",
    "<a href=#five.ten>5.10 Test set preperation and saving the best model </a>\n",
    "<br>\n",
    "<a href=#five.eleven>5.11 Test predicitions </a>\n",
    "<br>\n",
    "<a href=#five.twelve>5.12 CSV conversion </a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#six>6. Model performance</a></summary>\n",
    "<br>\n",
    "<a href=#six.one>6.1 What is performance analysis in machine learning</a>\n",
    "<br>\n",
    "<a href=#six.two>6.2 Evaluation of model</a>\n",
    "<br>\n",
    "<a href=#six.three>6.3 Assesment of the F-1 score according to both Train and Test sets </a>\n",
    "<br>\n",
    "<a href=#six.four>6.4 Analysing the dataframe</a>\n",
    "<br>\n",
    "<a href=#six.five>6.5 Plotting the F-1 Test performance from the Test data </a>\n",
    "<br>\n",
    "<a href=#six.six>6.6 Confusion matrix of the various models </a>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><a href=#six>7. Model Explanations</a></summary>\n",
    "<br>\n",
    "<a href=#seven.one>7.1 Best performing model</a>\n",
    "<br>\n",
    "<a href=#seven.two>7.2 Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " <a id=\"one\"></a>\n",
    " \n",
    " # **1.Importing Packages**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| *Description: Importing Packages*|\n",
    "| :--------------------------- |\n",
    ">In this section all the packages that may be needed during our analysis and the libraries that will be used throughout the analysis and modelling will be imported. \n",
    " |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"one.one\"></a>1.1 *Importing python packages that will be used in the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/caitlinmclaren/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/caitlinmclaren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/caitlinmclaren/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score, confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import urllib\n",
    "import spellchecker\n",
    "from textblob import TextBlob\n",
    "import autocorrect\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import  TweetTokenizer\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('Max_colwidth', 400)\n",
    "\n",
    "# suppress cell warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "# PARAMETER_CONSTANT = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "\n",
    " # **2. Loading the Data**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| *Description: Loading the data*  |\n",
    "| :--------------------------- |\n",
    "|\n",
    ">In this section the  `train.csv` and `test_with_no_lable.csv` will be loaded into the notebook.\n",
    " |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"two.one\"></a> 2.1 *Loading the Train and Test datasets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5163</td>\n",
       "      <td>57669</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1518349992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106343</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1206238739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146790</td>\n",
       "      <td>5459</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1076215539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106362</td>\n",
       "      <td>32296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1423042565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9041</td>\n",
       "      <td>366</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833375837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0    5163    57669     4.0  1518349992\n",
       "1  106343        5     4.5  1206238739\n",
       "2  146790     5459     5.0  1076215539\n",
       "3  106362    32296     2.0  1423042565\n",
       "4    9041      366     3.0   833375837"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Train dataset\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId\n",
       "0       1     2011\n",
       "1       1     4144\n",
       "2       1     5767\n",
       "3       1     6711\n",
       "4       1     7318"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Test dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "\n",
    "# **3. Exploratory Data Analysis (EDA)**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "|  *Description: Exploratory data analysis* |\n",
    "| :--------------------------- |\n",
    "| \n",
    ">In this section, there will be an in-depth analysis of all the variables in the dataframe. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"three.one\"></a> 3.1 *Why is EDA important?* \n",
    "\n",
    "&#10148; It helps to prepare the dataset for analysis. </br>\n",
    "&#10148; It allows a machine learning model to predict the dataset better. </br>\n",
    "&#10148; It gives more accurate results.  </br>\n",
    "&#10148; It also helps with choosing a better machine learning model. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "\n",
    "# **4. Data Engineering**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "|  *Description: Data engineering*  |\n",
    "| :--------------------------- |\n",
    "| \n",
    ">In this section the dataset will be cleaned and possible new new features created - as identified in the EDA phase. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "\n",
    "# **5. Modelling**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| *Description: Modelling*  |\n",
    "| :--------------------------- |\n",
    "| \n",
    ">In this section models will be built,namley: . |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "\n",
    "# **6.Model Performance**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| *Description: Model performance* |\n",
    "| :--------------------------- |\n",
    "| \n",
    ">In this section the models that were built will be compared relative to their performance and the best model will be selected. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "\n",
    "# **7. Model Explanation**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "|  *Description: Model explanation*  |\n",
    "| :--------------------------- |\n",
    "| \n",
    ">A brief explanation is given of which model preformed the best\n",
    "---\n",
    "\n",
    "![](https://imageio.forbes.com/specials-images/dam/imageserve/966248982/660x0.jpg?format=jpg&width=960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca2bc8e3f39d2931ba3f946aae372e8bb6c1cec41de64bd0d3a80050e300b4f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
